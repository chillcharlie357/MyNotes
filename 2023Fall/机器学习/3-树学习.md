---
aliases: 
tags: 
categories:
sticky:
thumbnail:
cover: 
excerpt: false
mathjax: true
comment: true
title: 3-树学习
date:  Tuesday,October 10th 2023
modified:  Tuesday,October 10th 2023
---

# 概念学习 Concept Learning

## 推理

- 演绎（正向）推理：已知$P\rightarrow Q$，P为真，则Q为真
- 反绎（溯因/反向）推理：已知$P\rightarrow Q$，Q为真，则P为真
- 归纳推理：已知前件为真，后件未必为真

符号学习（概念学习）是一类归纳推理

## 定义

- 定义：给定样例集合，以及每个样例是否属于某个概念，<font color="#ff0000">自动</font>地推断出该概念的一般定义

## 学习任务

![image.png](https://chillcharlie-img.oss-cn-hangzhou.aliyuncs.com/image%2F2023%2F09%2F26%2F03db83d384aab76905ec067aec304da5_20230926184910.png)

sunny+Rainy+cloudy

实例集合X  
目标概念c：定义在实例集上的布尔函数$c:X\rightarrow \{0,1\}$  
训练样例：正例$c(x)=1$，反例$c(x)=0$  
假设集H：每个假设h表示X上定义的布尔函数$h:X\rightarrow\{0,1\}$

概念学习：寻找一个假设h，使得$\forall x \in X,h(x)=c(x)$

最一般假设：$<?,?,?,?,?,?>$  
最特殊假设：$<\emptyset,\emptyset,\emptyset,\emptyset,\emptyset,\emptyset>$    

## 假设的一般到特殊序

更泛化：令$h_j$和$h_K$是定义在$X$上的布尔函数，若$h_j\ge_{g} h_k$当且仅当，

泛化：属性约束更弱 $general$  
特化：属性学习更强 $specific$

## Find-S算法：寻找极大特殊假设

1. 将h初始化为H中最特殊的假设
2. 对每个正例x
	- 对h的每个属性约束$a_i$，如果x满足$a_i$，那么不做任何处理
	- 否则将h中的$a_i$替换成x满足的另一个最一般的约束

对属性以**合取式**表示的假设空间,输出与正例一致的最特殊假设

![image.png](https://chillcharlie-img.oss-cn-hangzhou.aliyuncs.com/image%2F2023%2F09%2F26%2F2b4f2cf552e827c063d71834aa165528_20230926190654.png)  
![image.png](https://chillcharlie-img.oss-cn-hangzhou.aliyuncs.com/image%2F2023%2F09%2F26%2Ff9658bc2aac1c96f2dea4810a30c916e_20230926190659.png)

## 列表消除算法:List-Then-Eliminate

### 算法过程

1. 对**变型空间**$Version    Space$(假设空间$H$中所有假设的列表)
2. 对每个样例$<x,c(x)>$
	- 从变型空间中移除$h(X)\ne c(x)$的假设$h$
3. 输出$Version Space$的假设列表

要列出所有假设,不要现实

### 变型空间

- 一致 $Consistent$
	- 一个假设$h$与训练样例集合$D$一致$\iff$ $Consistent()$
- 变型空间
- 极大泛化
- 极大特化

![image.png](https://chillcharlie-img.oss-cn-hangzhou.aliyuncs.com/image%2F2023%2F10%2F10%2F381eb19e092270d873ba22df049562af_20231010184937.png)

**变型空间表示定理**

## 候选消除算法:Candidate-Eliminate

正例用于泛化$S$集合，搜索$S$集合  
反例用于特化$G$集合，缩小$G$集合

- **一致**：对每个假设h都符合当前见过的所有样本(h与D一致)

![image.png](https://chillcharlie-img.oss-cn-hangzhou.aliyuncs.com/image%2F2023%2F10%2F10%2F78eb0557d22b7c5fdf772a2ab1cac5cb_20231010184031.png)

# 归纳偏置

原假设空间时**合取式（有偏，与）**，而真实空间时由**析取式（无偏，或）** 表示  
无偏无法使用，无法进行泛化

幂集：集合$X$的所有子集的集合

## 定义

- 核心
	- 学习器从训练样例中泛化并推断新实例分类过程中所采用的策略
- 精确定义：
	- 学习器的归纳偏置为符合的前提集合B，通过B，则归纳推理可由演绎推理派生

## 不同归纳偏置

- 有偏程度不同的三种归纳学习算法
	1. 机械式学习器
	2. 候选消除算法
		- 偏置：所有的样本一定在假设空间里
	3. FIND-S

- 有偏性
	- 无归纳偏置
	- ${c\in H}$
	- ${c\in H}$+任何实例，除非可以有其他先验推出，否则都为反例

有偏性越强，则学习器的归纳能力越强

# 决策树学习

## 特点

- 特点
	- 实例：属性-值 对表示
	- 目标函数具备离散的输出值
	- 很好的健壮性（样例可以包含错误，缺少属性值）
	- <font color="#ff0000">可以学习析取表达式</font>
	- 推理具备可解释性
- 算法
	- ID3,C4.5
	- 搜索一个完整表示的假设空间，表示为**多个If-then规则**(可解释性)
- **归纳偏置**：
	- 优先选择较小的树，保证了在析取空间也具备泛化能力


## 问题设置

可能的实例集$X$，未知的目标函数$f:X\rightarrow Y$，假设函数集$H=\{h | h: X\rightarrow Y\}$

输入：未知目标函数$f$的训练实例$\{x+i,y_i\}$
输出：最佳近似f的假设$h\in H$

- 算法框架
	- 处理基本情况
	- 寻找最好的分类属性𝐴𝐴𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏
	- 用𝐴𝐴𝑏𝑏𝑏𝑏𝑏𝑏𝑏𝑏建立一个节点划分样例
	- 递归处理每一个划分，作为其子节点/子树

## 假设空间搜索


## ID3算法

1. 创建树的Root节点
2. 如果Examples的目标属性均为正，那么返回label="+"的单节点树Root
3. 如果Examples的目标属性均为反，那么返回label="-"的单节点树Root
4. 如果Attributes为“空”，那么返回单结点树Root，label设置 为Examples中最普遍的目标属性值
5. **否则**
	- $A\leftarrow Attributes$中分类Examples能力最好的属性
	- Root的决策属性$\leftarrow A$
	- 对A的每个可能取值$v_i$
		- 令$Examples$