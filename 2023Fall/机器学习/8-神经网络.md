---
aliases: 
tags:
  - 2023_Fall_机器学习
  - 课程
categories: 2023_Fall_机器学习
sticky:
thumbnail:
cover: 
excerpt: false
mathjax: true
comment: true
title: 8-神经网络
date: 2023-11-14 18:30
modified: 2023-12-29 10:15
---

# 1. 多层感知机MLP

多了hidden layer

## 1.1. 为什么需要隐藏层

隐藏层的神经元实际为**特征检测算子**，隐藏层神经元开始逐步发现刻画训练数据的突出特征。

## 1.2. 反向传播

- 误差反传（Back-propagation of error）的要素
	- 误差定义
	- Delta规则
	- 激活函数
	- 反传学习的推到（链式法则）

### 1.2.1. 误差定义

感知机：误差直接求和，单层感知机中N=1

$$
E=\sum\limits_{k=1}^{N}(y_{k}-t_{k})
$$

多层感知机：误差平方求和，防止正误差和负误差加起来为误差变小

$$
E(t,y)=\frac{1}{2}\sum\limits_{k=1}^{N}(y_{k} -t_{k})^{2}
$$

 1/2方便求导，不是必须

### 1.2.2. delta规则

- 基于误差平面
- 要求激活函数连续可微分
- 误差平面是神经网络表示的函数在训练数据集上累计的误差。每个权值向量都对应误差平面的一个点

$$
\Delta W_{k}=c(y_k-t_{k})f^`(W_{k}\times X_{k})X_{k}
$$

## 1.3. 反向传播算法 Back Propagation

- 前向阶段：网络突触权值固定，输入信号在网络中正向一层一层传播，直到到达输出端，获得网络输出

- 反向阶段：比较网络输出与期望输出，产生**误差信号**。误差信号通过网络反向传播，修正权值。

### 1.3.1. BP神经网络

- 三层或以上的结构
- 无反馈
- 层内无相连
- 输入+输出+隐藏层
- 采用误差反向传播算法

## 1.4. 激活函数

[[7-神经元#3. 激活函数]]

## 1.5. BP反向传播推导

![image.png](https://chillcharlie-img.oss-cn-hangzhou.aliyuncs.com/image%2F2023%2F11%2F14%2F19-50-11-07d38c65d0e4e233cd1f6c8c0311fd4a-20231114195010-79d6c9.png)

## 1.6. 随机梯度下降

- 最小化一个损失函数/目标函数

- 梯度下降
	- 批量梯度下降
	- 随机梯度下降
	- **Mini-batch**随机梯度下降
		- Batch size

# 2. 自动编码器 AutoEncoder

![image.png](https://chillcharlie-img.oss-cn-hangzhou.aliyuncs.com/image%2F2023%2F11%2F14%2F21-05-12-50677609ada91a4e88c32ece33c3bc6b-20231114210511-112107.png)

x -> encoder -> latent space -> decoder -> x

- 可以生成新的数据
- 去噪

# 3. 径向基网络 RBF

## 感受野 Receptive Fields

受人视网膜启发

- 高斯函数作为激活函数:
	- 神经元输出与输入数据何权值向量的距离成比例

$$
g(x,w,\delta)=exp(\frac{-||x-w||^2}{2\delta^2})
$$

![image.png](https://chillcharlie-img.oss-cn-hangzhou.aliyuncs.com/image%2F2023%2F11%2F21%2F18-58-44-ccd0a439953725f32a20e1f8fad41035-20231121185843-bc3fbd.png)

RBF层激活规则：基于距离，局部匹配  
MLP层激活规则：基于内积，全局匹配。计算$w^{T}x$时需要用到之前所有的x

![image.png](https://chillcharlie-img.oss-cn-hangzhou.aliyuncs.com/image%2F2023%2F11%2F21%2F18-55-11-39ef21cec6d1cec464af6f649a0771d2-20231121185510-248b35.png)

## RBF算法

求解的参数有三个：基函数的中心、方差和隐藏层到输出层的权值

1. 定义RBF的中心$c_k$
	- 随机选择数据点作为中心点
	- 均值
2. 用高斯函数计算RBF节点的行为
3. 用任意一种方式计算训练输出的权值
	- 用感知机
	- 计算RBF中心化的伪逆 

