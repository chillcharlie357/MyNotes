---
aliases: 
tags:
  - 2023_Fall_机器学习
  - 课程
categories: 2023_Fall_机器学习
sticky:
thumbnail:
cover: 
excerpt: false
mathjax: true
comment: true
title: 7-神经元
date: 2023-11-07 19:03
modified: 2023-12-29 10:15
---

# 1. Hebb法则

连接强度的调整值与输入输出的乘积成正比，经常出现的模式增强神经元的连接

# 2. MP神经元模型

![image.png](https://chillcharlie-img.oss-cn-hangzhou.aliyuncs.com/image%2F2023%2F11%2F07%2Ffabc679558d840c6d0dd65a0756fd57c_20231107193143.png)

输入：X  
权重：W  
输出：激活函数$f(net)=f(\sum\limits(w_{i}\times x_{i}))$

偏置单元：$x_{0}w_{0}$

单个神经元实现and/or，但不能实现xor

# 3. 激活函数

单位跃阶函数

- Sigmoid函数：$f(x)= \frac{1}{1+e^{-x}}$
	- 容易造成梯度消失，无法扩展模型深度
	- 导数为其本身的函数
	- 饱和激活函数

ReLU、Leaky ReLU

# 4. 感知机

早期的前馈式人工神经网络

## 4.1. 有监督的学习机制

![image.png](https://chillcharlie-img.oss-cn-hangzhou.aliyuncs.com/image%2F2023%2F11%2F07%2Fcb9a30166f357c94c2cb2a420187b7d7_20231107203652.png)

$\Delta W_i$当期望输出与实际输出不一致时，更新$W$

## 4.2. 学习算法

*假设样本线性可分*

1. 权值初始化
2. 输入样本对
3. 计算输出
4. 根据感知机学习规则调整权值
5. 回到2输入到下一堆样本，直到所有样本的实际输出值与期待输出相等

![image.png](https://chillcharlie-img.oss-cn-hangzhou.aliyuncs.com/image%2F2023%2F11%2F07%2F80c90b89aa30cd131819bace33e28609_20231107203845.png)

# 5. 线性可分性

## 5.1. 决策边界

鉴别函数定义的超平面$w^{T}x +b = 0$

## 5.2. 多分类的决策边界

每一个输出神经元定义一条决策边界  
多个神经元就决定多分类的决策边界

## 5.3. 感知机收敛理论

给定线性可分的数据集，感知机可以在有限次迭代中收敛到一个决策边界

定义$\gamma$式分离超平面与最接近的数据点之间的距离，则迭代次数的界为$\frac{1}{\gamma^2}$

## 5.4. 感知机局限

单层神经网络，不能解决非线性问题
