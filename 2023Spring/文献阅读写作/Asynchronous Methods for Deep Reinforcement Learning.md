
annotation-target::![[mniha16.pdf]]

>%%
>```annotation-json
>{"created":"2023-06-26T07:17:54.349Z","updated":"2023-06-26T07:17:54.349Z","document":{"title":"Asynchronous Methods for Deep Reinforcement Learning","link":[{"href":"urn:x-pdf:a8d10e7219703d191c29131303c6d5a1"},{"href":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/mniha16.pdf"}],"documentFingerprint":"a8d10e7219703d191c29131303c6d5a1"},"uri":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/mniha16.pdf","target":[{"source":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/mniha16.pdf","selector":[{"type":"TextPositionSelector","start":2589,"end":2744},{"type":"TextQuoteSelector","exact":" uses more memory and computation per realinteraction; and it requires off-policy learning algorithmsthat can update from data generated by an older policy","prefix":" replay has severaldrawbacks: it","suffix":".In this paper we provide a very"}]}]}
>```
>%%
>*%%PREFIX%%replay has severaldrawbacks: it%%HIGHLIGHT%% ==uses more memory and computation per realinteraction; and it requires off-policy learning algorithmsthat can update from data generated by an older policy== %%POSTFIX%%.In this paper we provide a very*
>%%LINK%%[[#^gxcm5s6ddds|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^gxcm5s6ddds


>%%
>```annotation-json
>{"created":"2023-06-26T07:18:23.725Z","updated":"2023-06-26T07:18:23.725Z","document":{"title":"Asynchronous Methods for Deep Reinforcement Learning","link":[{"href":"urn:x-pdf:a8d10e7219703d191c29131303c6d5a1"},{"href":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/mniha16.pdf"}],"documentFingerprint":"a8d10e7219703d191c29131303c6d5a1"},"uri":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/mniha16.pdf","target":[{"source":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/mniha16.pdf","selector":[{"type":"TextPositionSelector","start":2828,"end":2953},{"type":"TextQuoteSelector","exact":"Instead of experience replay, weasynchronously execute multiple agents in parallel, on mul-tiple instances of the environment","prefix":"for deepreinforcement learning. ","suffix":". This parallelism alsodecorrela"}]}]}
>```
>%%
>*%%PREFIX%%for deepreinforcement learning.%%HIGHLIGHT%% ==Instead of experience replay, weasynchronously execute multiple agents in parallel, on mul-tiple instances of the environment== %%POSTFIX%%. This parallelism alsodecorrela*
>%%LINK%%[[#^vyj152yegcm|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^vyj152yegcm
