annotation-target::![[rllib-zh.pdf]]

>%%
>```annotation-json
>{"created":"2023-06-26T03:22:11.263Z","updated":"2023-06-26T03:22:11.263Z","document":{"title":"rllib-zh.pdf","link":[{"href":"urn:x-pdf:0f5133139000ce6ca9ab8ea165042a06"},{"href":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf"}],"documentFingerprint":"0f5133139000ce6ca9ab8ea165042a06"},"uri":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf","target":[{"source":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf","selector":[{"type":"TextPositionSelector","start":1094,"end":1140},{"type":"TextQuoteSelector","exact":"通过组合和重用现有模块与算法实现来构建可拓展的强化学习算法对于该领域快速发展和进步至关重要。","prefix":"学习算法通常还必须重新实现分布式通信和执行的大部分内容。我们认为","suffix":"我们注意到实现强化学习平台的困难之处在于可伸缩性和可组合性，而这"}]}]}
>```
>%%
>*%%PREFIX%%学习算法通常还必须重新实现分布式通信和执行的大部分内容。我们认为%%HIGHLIGHT%% ==通过组合和重用现有模块与算法实现来构建可拓展的强化学习算法对于该领域快速发展和进步至关重要。== %%POSTFIX%%我们注意到实现强化学习平台的困难之处在于可伸缩性和可组合性，而这*
>%%LINK%%[[#^2hus7i1pj6c|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^2hus7i1pj6c


>%%
>```annotation-json
>{"created":"2023-06-26T03:22:58.101Z","updated":"2023-06-26T03:22:58.101Z","document":{"title":"rllib-zh.pdf","link":[{"href":"urn:x-pdf:0f5133139000ce6ca9ab8ea165042a06"},{"href":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf"}],"documentFingerprint":"0f5133139000ce6ca9ab8ea165042a06"},"uri":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf","target":[{"source":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf","selector":[{"type":"TextPositionSelector","start":3097,"end":3110},{"type":"TextQuoteSelector","exact":"通用且模块化的分层编程模型","prefix":"中。本文的贡献主要有如下三点：1. 我们为强化学习训练提出了一个","suffix":"（章节A.2）；2. 我们描述了RLlib，一个高度可扩展的强化"}]}]}
>```
>%%
>*%%PREFIX%%中。本文的贡献主要有如下三点：1. 我们为强化学习训练提出了一个%%HIGHLIGHT%% ==通用且模块化的分层编程模型== %%POSTFIX%%（章节A.2）；2. 我们描述了RLlib，一个高度可扩展的强化*
>%%LINK%%[[#^6jjgjr4pwfv|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^6jjgjr4pwfv


>%%
>```annotation-json
>{"created":"2023-06-26T03:23:04.311Z","updated":"2023-06-26T03:23:04.311Z","document":{"title":"rllib-zh.pdf","link":[{"href":"urn:x-pdf:0f5133139000ce6ca9ab8ea165042a06"},{"href":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf"}],"documentFingerprint":"0f5133139000ce6ca9ab8ea165042a06"},"uri":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf","target":[{"source":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf","selector":[{"type":"TextPositionSelector","start":3126,"end":3147},{"type":"TextQuoteSelector","exact":"RLlib，一个高度可扩展的强化学习算法库","prefix":"了一个通用且模块化的分层编程模型（章节A.2）；2. 我们描述了","suffix":"，以及如何在我们的代码库上面快速构建一系列强化学习算法（章节A."}]}]}
>```
>%%
>*%%PREFIX%%了一个通用且模块化的分层编程模型（章节A.2）；2. 我们描述了%%HIGHLIGHT%% ==RLlib，一个高度可扩展的强化学习算法库== %%POSTFIX%%，以及如何在我们的代码库上面快速构建一系列强化学习算法（章节A.*
>%%LINK%%[[#^smyyzos664|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^smyyzos664


>%%
>```annotation-json
>{"created":"2023-06-26T03:23:11.859Z","updated":"2023-06-26T03:23:11.859Z","document":{"title":"rllib-zh.pdf","link":[{"href":"urn:x-pdf:0f5133139000ce6ca9ab8ea165042a06"},{"href":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf"}],"documentFingerprint":"0f5133139000ce6ca9ab8ea165042a06"},"uri":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf","target":[{"source":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf","selector":[{"type":"TextPositionSelector","start":3187,"end":3197},{"type":"TextQuoteSelector","exact":"讨论了这一框架的性能","prefix":"的代码库上面快速构建一系列强化学习算法（章节A.3）；3. 我们","suffix":"（章节A.4），并表明RLlib 在各种强化学习算法中和众多框架"}]}]}
>```
>%%
>*%%PREFIX%%的代码库上面快速构建一系列强化学习算法（章节A.3）；3. 我们%%HIGHLIGHT%% ==讨论了这一框架的性能== %%POSTFIX%%（章节A.4），并表明RLlib 在各种强化学习算法中和众多框架*
>%%LINK%%[[#^xaeuczlyn5i|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xaeuczlyn5i


>%%
>```annotation-json
>{"created":"2023-06-26T03:53:18.463Z","updated":"2023-06-26T03:53:18.463Z","document":{"title":"rllib-zh.pdf","link":[{"href":"urn:x-pdf:0f5133139000ce6ca9ab8ea165042a06"},{"href":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf"}],"documentFingerprint":"0f5133139000ce6ca9ab8ea165042a06"},"uri":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf","target":[{"source":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf","selector":[{"type":"TextPositionSelector","start":6109,"end":6119},{"type":"TextQuoteSelector","exact":"算法相关的策略计算图","prefix":"ors]))A.3.3 策略优化器RLlib 将算法的实现分为与","suffix":"和与算法无关的策略优化器两个部分。策略优化器负责分布式采样、参数"}]}]}
>```
>%%
>*%%PREFIX%%ors]))A.3.3 策略优化器RLlib 将算法的实现分为与%%HIGHLIGHT%% ==算法相关的策略计算图== %%POSTFIX%%和与算法无关的策略优化器两个部分。策略优化器负责分布式采样、参数*
>%%LINK%%[[#^fc0yr6pq6v4|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^fc0yr6pq6v4


>%%
>```annotation-json
>{"created":"2023-06-26T03:53:28.884Z","updated":"2023-06-26T03:53:28.884Z","document":{"title":"rllib-zh.pdf","link":[{"href":"urn:x-pdf:0f5133139000ce6ca9ab8ea165042a06"},{"href":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf"}],"documentFingerprint":"0f5133139000ce6ca9ab8ea165042a06"},"uri":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf","target":[{"source":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf","selector":[{"type":"TextPositionSelector","start":6121,"end":6131},{"type":"TextQuoteSelector","exact":"算法无关的策略优化器","prefix":"策略优化器RLlib 将算法的实现分为与算法相关的策略计算图和与","suffix":"两个部分。策略优化器负责分布式采样、参数更新和管理重放缓冲区等性"}]}]}
>```
>%%
>*%%PREFIX%%策略优化器RLlib 将算法的实现分为与算法相关的策略计算图和与%%HIGHLIGHT%% ==算法无关的策略优化器== %%POSTFIX%%两个部分。策略优化器负责分布式采样、参数更新和管理重放缓冲区等性*
>%%LINK%%[[#^rqi10kaks0l|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^rqi10kaks0l


>%%
>```annotation-json
>{"created":"2023-06-27T06:51:58.923Z","updated":"2023-06-27T06:51:58.923Z","document":{"title":"rllib-zh.pdf","link":[{"href":"urn:x-pdf:0f5133139000ce6ca9ab8ea165042a06"},{"href":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf"}],"documentFingerprint":"0f5133139000ce6ca9ab8ea165042a06"},"uri":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf","target":[{"source":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf","selector":[{"type":"TextPositionSelector","start":167,"end":202},{"type":"TextQuoteSelector","exact":"它能够让一系列的强化学习算法达到高性能、可拓展和大量代码重用这些特性。","prefix":"一个可拓展的强化学习软件平台中，我们展示了我们所提出理论的好处：","suffix":"RLlib 是开源项目Ray 的一部分，文档位于https://"}]}]}
>```
>%%
>*%%PREFIX%%一个可拓展的强化学习软件平台中，我们展示了我们所提出理论的好处：%%HIGHLIGHT%% ==它能够让一系列的强化学习算法达到高性能、可拓展和大量代码重用这些特性。== %%POSTFIX%%RLlib 是开源项目Ray 的一部分，文档位于https://*
>%%LINK%%[[#^yl5gkv3s5ua|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^yl5gkv3s5ua


>%%
>```annotation-json
>{"created":"2023-06-27T07:31:55.925Z","updated":"2023-06-27T07:31:55.925Z","document":{"title":"rllib-zh.pdf","link":[{"href":"urn:x-pdf:0f5133139000ce6ca9ab8ea165042a06"},{"href":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf"}],"documentFingerprint":"0f5133139000ce6ca9ab8ea165042a06"},"uri":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf","target":[{"source":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf","selector":[{"type":"TextPositionSelector","start":2643,"end":2647},{"type":"TextQuoteSelector","exact":"等效算法","prefix":"分层控制模型的基础上搭建强化学习框架，有如下几个重要优势：首先，","suffix":"在实际应用中往往更容易实现，因为分布式控制逻辑完全封装在一个进程"}]}]}
>```
>%%
>*%%PREFIX%%分层控制模型的基础上搭建强化学习框架，有如下几个重要优势：首先，%%HIGHLIGHT%% ==等效算法== %%POSTFIX%%在实际应用中往往更容易实现，因为分布式控制逻辑完全封装在一个进程*
>%%LINK%%[[#^yb8t0j5jr1|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^yb8t0j5jr1


>%%
>```annotation-json
>{"created":"2023-06-27T07:51:46.959Z","updated":"2023-06-27T07:51:46.959Z","document":{"title":"rllib-zh.pdf","link":[{"href":"urn:x-pdf:0f5133139000ce6ca9ab8ea165042a06"},{"href":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf"}],"documentFingerprint":"0f5133139000ce6ca9ab8ea165042a06"},"uri":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf","target":[{"source":"vault:/2023Spring/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%E5%86%99%E4%BD%9C/papers/rllib-zh.pdf","selector":[{"type":"TextPositionSelector","start":1194,"end":1232},{"type":"TextQuoteSelector","exact":"主张围绕逻辑集中式程序控制（逻辑中控）和并行封装的原理构造分布式强化学习组件","prefix":"缩性和可组合性，而这两种特性不能通过单线程库轻松实现。为此，我们","suffix":"。我们根据这些原则构建了RLlib，结果不仅能够实现各种最新的强"}]}]}
>```
>%%
>*%%PREFIX%%缩性和可组合性，而这两种特性不能通过单线程库轻松实现。为此，我们%%HIGHLIGHT%% ==主张围绕逻辑集中式程序控制（逻辑中控）和并行封装的原理构造分布式强化学习组件== %%POSTFIX%%。我们根据这些原则构建了RLlib，结果不仅能够实现各种最新的强*
>%%LINK%%[[#^ug3905dx3tl|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ug3905dx3tl
