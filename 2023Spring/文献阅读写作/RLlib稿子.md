
# 背景

背景：强化学习算法设计复杂（大多数是完全分布式），传统方案的可扩展性和代码复用性差。

RLlib是一个**基于Ray**分布式计算框架的开源强化学习库，它提供了一组高级接口和算法，用于实现和测试各种强化学习技术。

# 分层控制模型

![image.png](https://chillcharlie-img.oss-cn-hangzhou.aliyuncs.com/image%2F2023%2F06%2F27%2F506f69fb3391fd6ed5bc238d945d800e_20230627161619.png)

区别于传统的完全分布式模型，RLlib使用分层控制模型。
1. RLlib利用Ray的分布式计算功能，实现了**高效的分布式训练**，包括任务并行、数据并行和深度学习模型并行。这使得RLlib能够处理大规模的强化学习工作负载。
2. RLlib的**设计目标**是通过组合和重用现有模块与算法实现来构建可拓展的强化学习算法，不需要对每个任务从零开始重新构建代码。使用分层控制，组件可以保持不变，并且可以作为远程任务简单调用。
3. 封装了多种RL训练算法，由于开放的体系结构，也允许继续扩展。
# 设计原则

基于**逻辑集中式程序控制**（逻辑中控）和**并行封装**的原则。

- 逻辑中控(Logically centralized control)
	- 管理多个智能体（Agent）
	- 把分布式计算任务的各个子任务分配到不同节点上，协调子任务之间的通信

- 并行封装(parallelism encapsulation)
	- 把并行计算的接口和实现分离，隐藏复杂的细节，使得用户可以更方便地进行并行计算
	- 封装后也可以更好地代码复用



